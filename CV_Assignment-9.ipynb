{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab86dc16",
   "metadata": {},
   "source": [
    "# CV_Assignment-9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fead7",
   "metadata": {},
   "source": [
    "1. What are the advantages of a CNN for image classification over a completely linked DNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f096e",
   "metadata": {},
   "source": [
    "The main advantages of a Convolutional Neural Network (CNN) for image classification over a completely linked Deep Neural Network (DNN) are that it can generalize better with fewer training examples, automatically detects important features without any human supervision, and has prior knowledge of how pixels are organized, allowing it to detect patterns in the data. Additionally, CNNs use dimensionality reduction to reduce the number of parameters in an image and can observe distinct features and connect them with the image input provided to give a classification output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e3821",
   "metadata": {},
   "source": [
    "2. Consider a CNN with three convolutional layers, each of which has three kernels, a stride of two, and SAME padding. The bottom layer generates 100 function maps, the middle layer 200, and the top layer 400. RGB images with a size of 200 x 300 pixels are used as input. How many criteria does the CNN have in total? How much RAM would this network need when making a single instance prediction if we're using 32-bit floats? What if you were to practice on a batch of 50 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb86f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "544c8ceb",
   "metadata": {},
   "source": [
    "3. What are five things you might do to fix the problem if your GPU runs out of memory while training a CNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7319ba5",
   "metadata": {},
   "source": [
    "1. Use an efficient input pipeline to improve memory usage[1].\n",
    "2. Restrict your CNN by making it smaller and simpler, possibly by inserting a pooling layer at the front[2].\n",
    "3. Incrementally increase the batch size until you reach the maximum memory capacity of your GPU[3].\n",
    "4. Enable dynamic memory allocation to allow TensorFlow or Keras to allocate only as much GPU memory as needed[3].\n",
    "5. Use layer reusing techniques like DenseNet architecture to save training time and memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a2e5d5",
   "metadata": {},
   "source": [
    "4. Why would you use a max pooling layer instead with a convolutional layer of the same stride ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f3cce",
   "metadata": {},
   "source": [
    "You would use a max pooling layer instead of a convolutional layer of the same stride because pooling is a cheaper operation than convolution, both in terms of memory and computation. Additionally, when convolutions with strides are better than pooling, it can help reduce overfitting and improve performance by preserving more information about the input. However, there are cases where replacing max-pooling with a convolutional layer with increased stride does not result in loss of accuracy on several image datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa84a66",
   "metadata": {},
   "source": [
    "5. When would a local response normalization layer be useful ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9874b",
   "metadata": {},
   "source": [
    "A local response normalization layer would be useful when dealing with ReLU neurons, as it helps to square-normalize the pixel values in a feature map within a local neighborhood, implements the idea of lateral inhibition, and makes the neurons more sensitive than their neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff3679",
   "metadata": {},
   "source": [
    "6. In comparison to LeNet-5, what are the main innovations in AlexNet? What about GoogLeNet and ResNet's core innovations ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd7cf5b",
   "metadata": {},
   "source": [
    "In comparison to LeNet-5, the main innovations in AlexNet are the use of ReLU activation functions, dropout layers, and data augmentation. GoogLeNet introduced inception modules which made it possible to have a much deeper net than previous CNN architectures. ResNet's core innovation is the introduction of residual learning, which allows for training of very deep networks with hundreds or thousands of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581edca",
   "metadata": {},
   "source": [
    "7. On MNIST, build your own CNN and strive to achieve the best possible accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a307c64",
   "metadata": {},
   "source": [
    "To build a CNN for MNIST handwritten digit recognition, you would need to load and transform the data[1][2][3][4], design a model using keras with tensorflow backend[2], train and test the model[4], and choose an appropriate CNN architecture[5]. To achieve the best possible accuracy, you would need to experiment with different architectures, hyperparameters, and regularization techniques. Some common approaches include increasing the depth of the network, adding more convolutional layers, using dropout or batch normalization to prevent overfitting, and tuning learning rate or optimizer parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583db957",
   "metadata": {},
   "source": [
    "8. Using Inception v3 to classify broad images.\n",
    "Images of different animals can be downloaded. Load them in Python using the matplotlib.image.mpimg.imread() or scipy.misc.imread() functions, for example. Resize and/or crop them to 299 x 299 pixels, and make sure they only have three channels (RGB) and no transparency. The photos used to train the Inception model were preprocessed to have values ranging from -1.0 to 1.0, so make sure yours do as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca18df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e51bffd2",
   "metadata": {},
   "source": [
    "9. Large-scale image recognition using transfer learning.\n",
    "Make a training set of at least 100 images for each class. You might, for example, identify your own photos based on their position (beach, mountain, area, etc.) or use an existing dataset, such as the flowers dataset or MIT's places dataset (requires registration, and it is huge).\n",
    "Create a preprocessing phase that resizes and crops the image to 299 x 299 pixels while also adding some randomness for data augmentation.\n",
    "Using the previously trained Inception v3 model, freeze all layers up to the bottleneck layer (the last layer before output layer) and replace output layer with appropriate number of outputs for your new classification task (e.g., the flowers dataset has five mutually exclusive classes so the output layer must have five neurons and use softmax activation function).\n",
    "Separate the data into two sets: a training and a test set. The training set is used to train the model, and the test set is used to evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0647cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

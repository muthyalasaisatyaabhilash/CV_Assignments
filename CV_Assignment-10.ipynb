{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e906dea",
   "metadata": {},
   "source": [
    "# CV_Assignment-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdbce62",
   "metadata": {},
   "source": [
    "1. What are the advantages of a CNN for image classification over a completely linked DNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c5e5b",
   "metadata": {},
   "source": [
    "The main advantages of a Convolutional Neural Network (CNN) for image classification over a completely linked Deep Neural Network (DNN) are that it can generalize better with fewer training examples automatically detects important features without any human supervision, and has prior knowledge of how pixels are organized, allowing it to detect patterns in the data. Additionally, CNNs use dimensionality reduction to reduce the number of parameters in an image and can observe distinct features and connect them with the image input provided to give a classification output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f36e1",
   "metadata": {},
   "source": [
    "2. Consider a CNN with three convolutional layers, each of which has three kernels, a stride of two, and SAME padding. The bottom layer generates 100 function maps, the middle layer 200, and the top layer 400. RGB images with a size of 200 x 300 pixels are used as input. How many criteria does the CNN have in total? How much RAM would this network need when making a single instance prediction if we're using 32-bit floats? What if you were to practice on a batch of 50 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d29c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef63a38d",
   "metadata": {},
   "source": [
    "3. What are five things you might do to fix the problem if your GPU runs out of memory while training a CNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e4e9e",
   "metadata": {},
   "source": [
    "1. Reduce the size of your model by making it smaller and simpler[1].\n",
    "2. Use a pooling layer at the front of your model[1].\n",
    "3. Use a transformation called \"lowering\" to efficiently execute small convolutions used in deep neural networks[2].\n",
    "4. Split the batch of samples into smaller mini-batches, where each mini-batch is processed sequentially on the GPU[3].\n",
    "5. Load only a subset of images into memory at any given time, rather than loading all images at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612a63a",
   "metadata": {},
   "source": [
    "4. Why would you use a max pooling layer instead with a convolutional layer of the same stride ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832f6f6",
   "metadata": {},
   "source": [
    "You would use a max pooling layer instead of a convolutional layer of the same stride because max pooling is a fixed operation and replacing it with a strided convolution can also be seen as learning. Additionally, when pooling is better than convolutions with strides, it can help reduce overfitting and improve performance by helping the network to generalize better. However, there are cases where stride-2 convolution seems better than max-pooling because it preserves more information about the input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6780a87d",
   "metadata": {},
   "source": [
    "5. When would a local response normalization layer be useful ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a509653",
   "metadata": {},
   "source": [
    "A local response normalization layer would be useful when dealing with ReLU neurons because they have unbounded activations, and we need local response normalization (LRN) to normalize them. LRN is a non-trainable layer that square-normalizes the pixel values in a feature map within a local neighborhood. It is useful for implementing lateral inhibition, which helps the neurons become more sensitive than their neighbors by identifying high-frequency features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8afa5c",
   "metadata": {},
   "source": [
    "6. In comparison to LeNet-5, what are the main innovations in AlexNet? What about GoogLeNet and ResNet's core innovations ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5683f6",
   "metadata": {},
   "source": [
    "In comparison to LeNet-5, the main innovations in AlexNet are the use of ReLU activation functions, dropout layers, and data augmentation. GoogLeNet introduced inception modules which made it possible to have a much deeper net than previous CNN architectures. ResNet's core innovation is the introduction of residual learning, which allows for training of very deep networks with hundreds or thousands of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa34b34",
   "metadata": {},
   "source": [
    "7. On MNIST, build your own CNN and strive to achieve the best possible accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6b794",
   "metadata": {},
   "source": [
    "To build a CNN for MNIST handwritten digit recognition, you would need to load and transform the data, design a model using keras with tensorflow backend, train and test the model, and choose an appropriate CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a06d08e",
   "metadata": {},
   "source": [
    "8. Using Inception v3 to classify broad images.\n",
    "Images of different animals can be downloaded. Load them in Python using the matplotlib.image.mpimg.imread() or scipy.misc.imread() functions, for example. Resize and/or crop them to 299 x 299 pixels, and make sure they only have three channels (RGB) and no transparency. The photos used to train the Inception model were preprocessed to have values ranging from -1.0 to 1.0, so make sure yours do as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8187908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed88fb65",
   "metadata": {},
   "source": [
    "9. Large-scale image recognition using transfer learning.\n",
    "Make a training set of at least 100 images for each class. You might, for example, identify your own photos based on their position (beach, mountain, area, etc.) or use an existing dataset, such as the flowers dataset or MIT's places dataset (requires registration, and it is huge).\n",
    "Create a preprocessing phase that resizes and crops the image to 299 x 299 pixels while also adding some randomness for data augmentation.\n",
    "Using the previously trained Inception v3 model, freeze all layers up to the bottleneck layer (the last layer before output layer) and replace output layer with appropriate number of outputs for your new classification task (e.g., the flowers dataset has five mutually exclusive classes so the output layer must have five neurons and use softmax activation function).\n",
    "Separate the data into two sets: a training and a test set. The training set is used to train the model, and the test set is used to evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7870a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

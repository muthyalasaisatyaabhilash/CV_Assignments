{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b071bc",
   "metadata": {},
   "source": [
    "# Assignment 03 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed445a",
   "metadata": {},
   "source": [
    "#### 1. After each stride-2 conv, why do we double the number of filters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0feda3",
   "metadata": {},
   "source": [
    "After each stride-2 convolution, the activation map dimension is reduced by half. To maintain the same computation as the network gets deeper, we double the number of filters. This is because a stride 2 conv with default padding and kernel size will reduce the activation map dimension by half"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804ecc1",
   "metadata": {},
   "source": [
    "#### 2. Why do we use a larger kernel with MNIST (with simple cnn) in the first conv ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a7c3d",
   "metadata": {},
   "source": [
    "We use a larger kernel with MNIST in the first convolutional layer because it helps to capture more features from the input image. This can help to improve accuracy while minimizing computational complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300559d",
   "metadata": {},
   "source": [
    "#### 3. What data is saved by ActivationStats for each layer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61771ea2",
   "metadata": {},
   "source": [
    "ActivationStats saves the activations of all modules in a layer. It provides utilities for plotting the activations during training. The output is generated by passing the transformed input through an activation function at each layer. Save To Layer File is a geoprocessing tool that creates a layer file (.lyrx) that references geographic data stored on disk. Data source classes should not know how the data is saved, for example, in a database or in a file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246d2fe",
   "metadata": {},
   "source": [
    "#### 4. How do we get a learner's callback after they've completed training ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf72b6",
   "metadata": {},
   "source": [
    "To get a learner's callback after they've completed training, we can use the after_fit event. This is called after the model has finished training. Fastai provides several callbacks that can be used to customize the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8aa18",
   "metadata": {},
   "source": [
    "#### 5. What are the drawbacks of activations above zero ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57727b9",
   "metadata": {},
   "source": [
    "The drawbacks of activations above zero include the potential for a vanishing gradient, non-differentiability at zero, and being unbounded. Additionally, sigmoid activation functions have become less popular due to their drawbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4effd",
   "metadata": {},
   "source": [
    "#### 6.Draw up the benefits and drawbacks of practicing in larger batches ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04f52b",
   "metadata": {},
   "source": [
    "Practicing in larger batches can lead to faster convergence and fewer batches. However, it can also lead to poor generalization performance, increased oscillation, and lower accuracy. The optimal batch size depends on the specific problem being solved and the available computational resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac40b1",
   "metadata": {},
   "source": [
    "#### 7. Why should we avoid starting training with a high learning rate ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53845399",
   "metadata": {},
   "source": [
    "We should avoid starting training with a high learning rate because it can lead to slow convergence or even failure to converge. A value too small may result in a long training process that could get stuck, whereas a value too large may cause the model to diverge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e94190",
   "metadata": {},
   "source": [
    "#### 8. What are the pros of studying with a high rate of learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ca0d09",
   "metadata": {},
   "source": [
    "There are no pros of studying with a high rate of learning. In fact, it can lead to slow convergence or even failure to converge. A value too small may result in a long training process that could get stuck, whereas a value too large may cause the model to diverge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84baff66",
   "metadata": {},
   "source": [
    "#### 9. Why do we want to end the training with a low learning rate ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab4476",
   "metadata": {},
   "source": [
    "We want to end the training with a low learning rate because smaller learning rates require more training epochs given the smaller changes made to the weights each update. A lower learning rate means more training time, which results in increased cloud GPU costs. However, if the learning rate is set too low, training will progress very slowly as you are making very tiny updates to the weights in your network. If you set your learning rate too low, your model will converge. The learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99337545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
